// Enable Wave for container management
wave {
    enabled = true
    freeze  = true
}

conda {
    enabled = true
    channels = ['conda-forge', 'bioconda', 'defaults']
}

// Global resource limits
executor {
    cpus = 105
    memory = '450 GB'
}

// Process configuration
process {
    // Global defaults
    cpus = { check_max(4, 'cpus') }
    memory = { check_max(8.GB * task.attempt, 'memory') }
    time = { check_max(4.h * task.attempt, 'time') }
    
    // Error strategy
    errorStrategy = { task.exitStatus in ((130..145) + 104) ? 'retry' : 'finish' }
    maxRetries = 1
    maxErrors = '-1'
    
    // Process-specific resource allocation
    withName: 'SPLIT_BAM' {
        cpus = { check_max(80, 'cpus') }
        memory = { check_max(4.GB * task.attempt, 'memory') }
        time = { check_max(2.h * task.attempt, 'time') }
        maxForks = 1  // Only one BAM to split
    }
    
    withName: 'BAMLEFTALIGN' {
        cpus = { check_max(4, 'cpus') }
        memory = { check_max(8.GB * task.attempt, 'memory') }
        time = { check_max(6.h * task.attempt, 'time') }
        maxForks = 25  // Allow all chromosomes to run in parallel
    }
    
    withName: 'ADD_READ_GROUPS' {
        conda = "bioconda::picard=2.23.0"
        cpus = { check_max(2, 'cpus') }
        memory = { check_max(12.GB * task.attempt, 'memory') }
        time = { check_max(2.h * task.attempt, 'time') }
        maxForks = 25
    }
    
    withName: 'REALIGNER_TARGET_CREATOR' {
        cpus = { check_max(2, 'cpus') }
        memory = { check_max(15.GB * task.attempt, 'memory') }
        time = { check_max(4.h * task.attempt, 'time') }
        maxForks = 25  // Allow all chromosomes to run in parallel
    }
    
    withName: 'EXPAND_REGIONS' {
        conda = "bioconda::bedtools=2.30.0"
        cpus = { check_max(1, 'cpus') }
        memory = { check_max(1.GB * task.attempt, 'memory') }
        time = { check_max(30.min * task.attempt, 'time') }
        maxForks = 25  // Allow all chromosomes to run in parallel
    }
    
    withName: 'ABRA_REALIGNMENT' {
         conda = "bioconda::abra2=2.23"
        // Adjusted for parallel execution: 105 CPUs / 6 processes = ~17 CPUs each
        // 450 GB / 6 processes = 75 GB each
        cpus = { check_max(17, 'cpus') }
        memory = { check_max(75.GB * task.attempt, 'memory') }
        time = { check_max(12.h * task.attempt, 'time') }
        maxForks = 6  // Limit to 6 ABRA processes running simultaneously
        // This allows: 6 * 17 CPUs = 102 CPUs, 6 * 75 GB = 450 GB
    }
    
    withName: 'MERGE_BAM' {
        conda = "bioconda::samtools=1.3.1"
        cpus = { check_max(8, 'cpus') }
        memory = { check_max(16.GB * task.attempt, 'memory') }
        time = { check_max(4.h * task.attempt, 'time') }
        maxForks = 1  // Only one merge process needed
    }
}

// Function to ensure that resource requirements don't go beyond maximum available resources
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}

// Parameters
params {
    // Input files
    input_bam = null
    reference_fasta = null
    genome_file = null  // Two-column tab-delimited file: chr length
    
    // Output directory
    outdir = "results"
    
    // Tool parameters
    expand_bp = 160
    threads = 4
    
    // Resource limits
    max_memory = '450.GB'
    max_cpus = 105
    max_time = '240.h'
    
    // Tool versions (following paper specifications)
    samtools_version = "1.3.1"
    freebayes_version = "1.2.0"
    abra_version = "2.23"
    gatk_version = "3.8"
    bedtools_version = "2.21.0"
    picard_version = "2.23.0"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

// Execution reports
timeline {
    enabled = true
    overwrite = true 
    file = "${params.outdir}/pipeline_info/execution_timeline.html"
}
report {
    enabled = true
    overwrite = true 
    file = "${params.outdir}/pipeline_info/execution_report.html"
}
trace {
    enabled = true
    overwrite = true 
    file = "${params.outdir}/pipeline_info/execution_trace.txt"
}
dag {
    enabled = true
    overwrite = true 
    file = "${params.outdir}/pipeline_info/pipeline_dag.svg"
}

// Manifest
manifest {
    name = 'pangenome-realignment'
    author = 'Juls'
    description = 'BAM realignment pipeline following Human Pangenome draft 2023 guidelines'
    mainScript = 'main.nf'
    nextflowVersion = '>=22.04.0'
    version = '1.0.0'
}
